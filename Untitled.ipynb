{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47dc262-808d-4a5d-85d7-aa373e7d6476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from niclassify.core.trim.trim import trim\n",
    "from pathlib import Path\n",
    "from niclassify.core.interfaces.handler import Handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f0cc920-b035-4683-9620-35fea6a48858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from Bio import SeqIO\n",
    "from tempfile import NamedTemporaryFile\n",
    "import shutil\n",
    "from collections import Counter\n",
    "import os\n",
    "from Bio.Seq import Seq\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a5ee67d-3487-4d39-90b8-c033e632875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = Path(\"./testing/hemiptera/ma.fasta\").resolve()\n",
    "output_file = Path(\"./testing/hemiptera/ma-trim.fasta\").resolve()\n",
    "handler = Handler()\n",
    "min_agreement = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0dc7a363-ac5a-4af0-9f73-770707d42201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "# Make sure we're reading the fasta fine\n",
    "read = 0\n",
    "with open(input_file, \"r\", encoding=\"utf8\") as input_fasta:\n",
    "    frames = Counter()\n",
    "    contaminant_sequences = set()\n",
    "    for record in SeqIO.parse(input_fasta, format=\"fasta\"):\n",
    "        read += 1\n",
    "print(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68f276dd-ec26-444d-9d2c-2017ee724d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Instead of this, get all valid reading frames for each seq\n",
    "then take the most common valid reading frame\n",
    "discard contaminants with no valid reading frame\n",
    "then for each seq,\n",
    "if it has the most common as a valid frame, use that\n",
    "else if it has the completment of that reading frame, use that\n",
    "otherwise, add it to list of invalid reading frame sequences\n",
    "\n",
    "then:\n",
    "report contaminants\n",
    "report invalids\n",
    "write out\n",
    "\"\"\"\n",
    "with open(input_file, \"r\", encoding=\"utf8\") as input_fasta:\n",
    "    frames = Counter()\n",
    "    contaminant_sequences = set()\n",
    "    n_seq = 0\n",
    "    for record in SeqIO.parse(input_fasta, format=\"fasta\"):\n",
    "        n_seq += 1\n",
    "        success = False\n",
    "        for offset in range(-4, 4):\n",
    "            flip = False\n",
    "            if offset < 0:\n",
    "                flip = True\n",
    "                offset = abs(offset) - 1\n",
    "            seq = record.seq if not flip else record.seq.reverse_complement()\n",
    "            seq = seq.replace(\"-\", \"N\")\n",
    "            # seq = (\"N\" * ((3 * math.ceil(len(seq) / 3)) - len(seq))) + seq\n",
    "            # seq = (\"N\" * offset) + seq\n",
    "            seq = seq[offset:]\n",
    "            seq = seq + (\"N\" * (3 - len(seq) % 3))\n",
    "            test = Seq(seq).translate(table=\"Invertebrate Mitochondrial\", gap=\"-\")\n",
    "            if \"*\" not in test:\n",
    "                # print(f\"{flip} {offset} {test}\")\n",
    "                success = True\n",
    "                frames.update([(flip, offset)])\n",
    "        if not success:\n",
    "            n_seq -= 1\n",
    "            contaminant_sequences.add(record.id)\n",
    "        handler.debug(\n",
    "            \"Reading frame votes (offset, where negative is\",\n",
    "            \"reverse-complement and offset by abs - 2):\",\n",
    "        )\n",
    "        handler.debug(\n",
    "            \", \".join(\n",
    "                [f\"{offset}:{count / n_votes:.2f}\" for offset, count in frames.items()]\n",
    "            )\n",
    "        )\n",
    "        # if not any((count / n_votes >= min_agreement for count in frames.values())):\n",
    "        #     # os.unlink(tempfile_path)\n",
    "        #     handler.error(\n",
    "        #         \"Minimum reading frame offset agreement not met.\",\n",
    "        #         \"Your sequences may be heavily contaminated.\",\n",
    "        #         abort=True,\n",
    "        #     )\n",
    "\n",
    "        # # determine the best offset to use\n",
    "        # flip, offset = frames.most_common(1)[0]\n",
    "\n",
    "        # print(f\"flip: {flip}, offset: {offset}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "384805ce-c4ca-4cbe-a994-fefcb9021f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({(False, 0): 204, (False, 3): 204, (True, 1): 23})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c552d5-0c35-47f9-aba0-5318973d3e3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, 0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames.most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b12f31c-7ad3-4032-a159-a93ee70e35fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contaminant_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ec7fbd7-5ef1-4ade-86da-635e71075d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 0.11274509803921569]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[count / n_seq for count in frames.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "546ad716-098e-4e31-8d82-94903b59523a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Seq' object has no attribute 'expandtabs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtextwrap\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtextwrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/textwrap.py:396\u001b[0m, in \u001b[0;36mfill\u001b[0;34m(text, width, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fill a single paragraph of text, returning a new string.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \n\u001b[1;32m    389\u001b[0m \u001b[38;5;124;03mReformat the single paragraph in 'text' to fit in lines of no more\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;124;03mavailable keyword args to customize wrapping behaviour.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    395\u001b[0m w \u001b[38;5;241m=\u001b[39m TextWrapper(width\u001b[38;5;241m=\u001b[39mwidth, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/textwrap.py:368\u001b[0m, in \u001b[0;36mTextWrapper.fill\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfill\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    362\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"fill(text : string) -> string\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Reformat the single paragraph in 'text' to fit in lines of no\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    more than 'self.width' columns, and return a new string\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    containing the entire wrapped paragraph.\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/textwrap.py:356\u001b[0m, in \u001b[0;36mTextWrapper.wrap\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[1;32m    348\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"wrap(text : string) -> [string]\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \n\u001b[1;32m    350\u001b[0m \u001b[38;5;124;03m    Reformat the single paragraph in 'text' so it fits in lines of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;124;03m    converted to space.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 356\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfix_sentence_endings:\n\u001b[1;32m    358\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fix_sentence_endings(chunks)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/textwrap.py:342\u001b[0m, in \u001b[0;36mTextWrapper._split_chunks\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_split_chunks\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[0;32m--> 342\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_munge_whitespace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split(text)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/lib/python3.11/textwrap.py:151\u001b[0m, in \u001b[0;36mTextWrapper._munge_whitespace\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"_munge_whitespace(text : string) -> string\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03mMunge whitespace in text: expand tabs and convert all other\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03mwhitespace characters to spaces.  Eg. \" foo\\\\tbar\\\\n\\\\nbaz\"\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03mbecomes \" foo    bar  baz\".\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexpand_tabs:\n\u001b[0;32m--> 151\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpandtabs\u001b[49m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtabsize)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace_whitespace:\n\u001b[1;32m    153\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39municode_whitespace_trans)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Seq' object has no attribute 'expandtabs'"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "textwrap.fill(seq, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15891762-c8fe-4b22-8ecf-08311a934fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
